BEFORE STARTING:
The aim of this simple experiment is to try and implement transfer learning
by first training a network to predict the presence or absence of object A
in the image and then keep parts of this network fixed and retrain the
rest of the network to predict the same for object B. My aim is to get a
basic idea of how much of the network is required to be retrained and with
how much lesser data can we get a similar performance. My initial guess
before starting the experiment is that results are going to be dissapointing
if objects A and B are not much similar whereas they will be much better
if the objects are somehow similar where the notion of similarity is somewhat
unclear to me too. Let's hope that the network performs better than my
expectation. 

DATASETS:
I plan to use the CIFAR10 dataset. It has 10 classes. As "Object A", I will
use any 5 classes and as for "Object B", I will use the remaining 5 classes.

BASE MODEL:
The best models for CIFAR10 report accuracies of greater than 90%. But since the
aim of this experiment is not achieving higher accuracies, I have used a simple
neural network that gives an accuracy of about 74%.
After dividing the dataset, db_left contains images with targets 0-4 and db_right
contains classes from 5-9. The same model now gives an accuracy of around 82% for
both the split datasets.
However the overfitting is just too much. The training accuracy reaches to 
100% before the 20th epoch! So some changes are required. The new model we have
gives around 80% accuracy on the left dataset and 85% on the right dataset.
We will use the model trained on the right dataset to check the performances
on left dataset.

We have 5 layers: 3 conv layers, 1 fully connected hidden layer, 1 fully connected output layer

model_retrained 				dataset_size				final_accuracy

0 (no layer)						100%						0.069200
1 (output layer)					100%						0.696000
2 (fc layers)						100%						0.761200
3 (1 conv)							100%						0.780800
4 (2 conv)							100%						0.787800
5 (retrained all)					100%						0.794800

0 (no layer)						75%							0.069200
1 (output layer)					75%							0.649600
2 (fc layers)						75%							0.759000
3 (1 conv)							75%							0.768800
4 (2 conv)							75%							0.781000
5 (retrained all)					75%							0.787000

0 (no layer)						50%							0.069200
1 (output layer)					50%							0.647400
2 (fc layers)						50%							0.751400
3 (1 conv)							50%							0.755200
4 (2 conv)							50%							0.763800
5 (retrained all)					50%							0.764400

0 (no layer)						25%							0.069200
1 (output layer)					25%							0.646000
2 (fc layers)						25%							0.733200
3 (1 conv)							25%							0.735200
4 (2 conv)							25%							0.740800
5 (retrained all)					25%							0.728800

0 (no layer)						10%							0.069200
1 (output layer)					10%							0.635800
2 (fc layers)						10%							0.708200
3 (1 conv)							10%							0.706200
4 (2 conv)							10%							0.700600
5 (retrained all)					10%							0.695200


OBSERVATIONS:
Let's for a moment just go crazy and use the model trained on the left database
and see the results it gives for the right database. If everything goes well, the
accuracy should be less 20% (nothing better than random). Okay, I got an accuracy 
of around 6.5%, which is a less than what I expected but then again, hey, it's not the data
the model was made for. Let's try to redo this once more to make sure it was not just
an off chance and then move forward. Okay, the second time too I got similar accuracy.
Okay, so now let's get started with the actual experimentation.

So as expected, as we keep decreasing the size of the dataset, the maxima of
accuracy keeps shifting towards the model in which more layers are kept frozen.

Also, the more data we use, the better accuracy we get for a given model.

REFERENCES:
Transfer Learning Refresher: https://towardsdatascience.com/transfer-learning-946518f95666

plot 'one_hot.dat' with linespoints , 'binary_encoding.dat' with linespoints
plot 'data100.dat' with linespoints , 'data75.dat' with linespoints , 'data50.dat' with linespoints , 'data25.dat' with linespoints , 'data10.dat' with linespoints