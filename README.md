## Neural Network Experiments
These are some simple(!) Neural Network Experiments that I started doing in December 2018.
These are done only for learning purposes and it means that sometimes simplicity is perferred over accuracy/performance.
There might be better ways to do some things for which I might've chosen simple ways to make frequent observations easier.
I will keep adding to these when I do more work. For details, go to the folder of the corresponding experiment.
As of now, following are the contents:

1. Binary Encoding vs. One Hot Encoding

...Almost everywhere in literature, you will see that the output is encoded as a one-hot vector, i.e.
...the number of dimensions of the output is equal to the total number of classes, with the value
...corresponding to the correct class being 1 and rest all being 0. However, can we also use binary-encoding
...which only requires log(n) dimensions for target representation? How does it compare to the one-hot encoding?